{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to copy the weights for the HiFiGAN from the XTTS model and check that our model spits out the same thing as a sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first download TTS, and the model checkpoint for XTTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugdual/miniconda3/envs/xtts/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-09 18:59:16--  https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\n",
      "Resolving coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)... 3.67.33.93, 3.77.103.135\n",
      "Connecting to coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)|3.67.33.93|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://huggingface.co/coqui/XTTS-v2/resolve/main/model.pth [following]\n",
      "--2024-11-09 18:59:16--  https://huggingface.co/coqui/XTTS-v2/resolve/main/model.pth\n",
      "Resolving huggingface.co (huggingface.co)... 2600:9000:244f:f600:17:b174:6d00:93a1, 2600:9000:244f:3600:17:b174:6d00:93a1, 2600:9000:244f:e200:17:b174:6d00:93a1, ...\n",
      "Connecting to huggingface.co (huggingface.co)|2600:9000:244f:f600:17:b174:6d00:93a1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/3e/73/3e73be38940b0ce7d10274a3412defcd0d3c9ea879d08bc8761d46cf6bbde3fa/c7ea20001c6a0a841c77e252d8409f6a74fb423e79b3206a0771ba5989776187?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.pth%3B+filename%3D%22model.pth%22%3B&Expires=1731437957&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQzNzk1N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzNlLzczLzNlNzNiZTM4OTQwYjBjZTdkMTAyNzRhMzQxMmRlZmNkMGQzYzllYTg3OWQwOGJjODc2MWQ0NmNmNmJiZGUzZmEvYzdlYTIwMDAxYzZhMGE4NDFjNzdlMjUyZDg0MDlmNmE3NGZiNDIzZTc5YjMyMDZhMDc3MWJhNTk4OTc3NjE4Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=TVkpyMFHt3Ce7IRDJVxXrHAzqId28myz6qWcYurpcIwyj%7E5Ewh8wg3G9DYFFV9DEvMunR4-1HyNUpA5PFRx4gJwpc%7EiwUyJ9d2qu%7EaQ7NEJZUUE2bZTasA53p3sQWWq1WXCVR2%7ExbOxwuqvDixLtnMHW7aXtd0fXVHiqr85fAf64xhVVj84L9GpeoCmLZuzCEv72cXTEmQePZlNSlogWIqsYWkgLY7G25gb9wSKLekHYt-8lIUUg-Qum7tir%7EW3465wWGLuk9eOAy1skHeWhux6f1ZD5H2Alu7BRSM7reyumPVav1F-dzAJ%7Ebyhy4idHaEBA%7EKycwMOn%7Eds14tlhNg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2024-11-09 18:59:17--  https://cdn-lfs-us-1.hf.co/repos/3e/73/3e73be38940b0ce7d10274a3412defcd0d3c9ea879d08bc8761d46cf6bbde3fa/c7ea20001c6a0a841c77e252d8409f6a74fb423e79b3206a0771ba5989776187?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.pth%3B+filename%3D%22model.pth%22%3B&Expires=1731437957&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQzNzk1N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzNlLzczLzNlNzNiZTM4OTQwYjBjZTdkMTAyNzRhMzQxMmRlZmNkMGQzYzllYTg3OWQwOGJjODc2MWQ0NmNmNmJiZGUzZmEvYzdlYTIwMDAxYzZhMGE4NDFjNzdlMjUyZDg0MDlmNmE3NGZiNDIzZTc5YjMyMDZhMDc3MWJhNTk4OTc3NjE4Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=TVkpyMFHt3Ce7IRDJVxXrHAzqId28myz6qWcYurpcIwyj%7E5Ewh8wg3G9DYFFV9DEvMunR4-1HyNUpA5PFRx4gJwpc%7EiwUyJ9d2qu%7EaQ7NEJZUUE2bZTasA53p3sQWWq1WXCVR2%7ExbOxwuqvDixLtnMHW7aXtd0fXVHiqr85fAf64xhVVj84L9GpeoCmLZuzCEv72cXTEmQePZlNSlogWIqsYWkgLY7G25gb9wSKLekHYt-8lIUUg-Qum7tir%7EW3465wWGLuk9eOAy1skHeWhux6f1ZD5H2Alu7BRSM7reyumPVav1F-dzAJ%7Ebyhy4idHaEBA%7EKycwMOn%7Eds14tlhNg__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.162.38.126, 3.162.38.57, 3.162.38.37, ...\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.162.38.126|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1867929118 (1.7G) [application/zip]\n",
      "Saving to: ‘model.pth.1’\n",
      "\n",
      "model.pth.1           0%[                    ]   3.39M  1.92MB/s               "
     ]
    }
   ],
   "source": [
    "!wget \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
    "!wget \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone git@github.com:nguyenhoanganh2002/XTTSv2-Finetuning-for-New-Languages.git\n",
    "!mv XTTSv2-Finetuning-for-New-Languages/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now be able to load the model as it is used in the XTTSv2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "(32, 1, 3, 3)\n",
      "conv1.bias\n",
      "(32, 1, 1)\n",
      "batch_norm.weight\n",
      "(32,)\n",
      "batch_norm.bias\n",
      "(32,)\n",
      "batch_norm.axis_name\n",
      "batch\n",
      "batch_norm.inference\n",
      "False\n",
      "layer1.0.conv1.weight\n",
      "(32, 32, 3, 3)\n",
      "layer1.0.conv2.weight\n",
      "(32, 32, 3, 3)\n",
      "layer1.0.bn1.weight\n",
      "(32,)\n",
      "layer1.0.bn1.bias\n",
      "(32,)\n",
      "layer1.0.bn1.axis_name\n",
      "batch\n",
      "layer1.0.bn1.inference\n",
      "False\n",
      "layer1.0.bn2.weight\n",
      "(32,)\n",
      "layer1.0.bn2.bias\n",
      "(32,)\n",
      "layer1.0.bn2.axis_name\n",
      "batch\n",
      "layer1.0.bn2.inference\n",
      "False\n",
      "layer1.0.se.fc1.weight\n",
      "(4, 32)\n",
      "layer1.0.se.fc1.bias\n",
      "(4,)\n",
      "layer1.0.se.fc2.weight\n",
      "(32, 4)\n",
      "layer1.0.se.fc2.bias\n",
      "(32,)\n",
      "layer1.1.conv1.weight\n",
      "(32, 32, 3, 3)\n",
      "layer1.1.conv2.weight\n",
      "(32, 32, 3, 3)\n",
      "layer1.1.bn1.weight\n",
      "(32,)\n",
      "layer1.1.bn1.bias\n",
      "(32,)\n",
      "layer1.1.bn1.axis_name\n",
      "batch\n",
      "layer1.1.bn1.inference\n",
      "False\n",
      "layer1.1.bn2.weight\n",
      "(32,)\n",
      "layer1.1.bn2.bias\n",
      "(32,)\n",
      "layer1.1.bn2.axis_name\n",
      "batch\n",
      "layer1.1.bn2.inference\n",
      "False\n",
      "layer1.1.se.fc1.weight\n",
      "(4, 32)\n",
      "layer1.1.se.fc1.bias\n",
      "(4,)\n",
      "layer1.1.se.fc2.weight\n",
      "(32, 4)\n",
      "layer1.1.se.fc2.bias\n",
      "(32,)\n",
      "layer1.2.conv1.weight\n",
      "(32, 32, 3, 3)\n",
      "layer1.2.conv2.weight\n",
      "(32, 32, 3, 3)\n",
      "layer1.2.bn1.weight\n",
      "(32,)\n",
      "layer1.2.bn1.bias\n",
      "(32,)\n",
      "layer1.2.bn1.axis_name\n",
      "batch\n",
      "layer1.2.bn1.inference\n",
      "False\n",
      "layer1.2.bn2.weight\n",
      "(32,)\n",
      "layer1.2.bn2.bias\n",
      "(32,)\n",
      "layer1.2.bn2.axis_name\n",
      "batch\n",
      "layer1.2.bn2.inference\n",
      "False\n",
      "layer1.2.se.fc1.weight\n",
      "(4, 32)\n",
      "layer1.2.se.fc1.bias\n",
      "(4,)\n",
      "layer1.2.se.fc2.weight\n",
      "(32, 4)\n",
      "layer1.2.se.fc2.bias\n",
      "(32,)\n",
      "layer2.0.conv1.weight\n",
      "(64, 32, 3, 3)\n",
      "layer2.0.conv2.weight\n",
      "(64, 64, 3, 3)\n",
      "layer2.0.bn1.weight\n",
      "(64,)\n",
      "layer2.0.bn1.bias\n",
      "(64,)\n",
      "layer2.0.bn1.axis_name\n",
      "batch\n",
      "layer2.0.bn1.inference\n",
      "False\n",
      "layer2.0.bn2.weight\n",
      "(64,)\n",
      "layer2.0.bn2.bias\n",
      "(64,)\n",
      "layer2.0.bn2.axis_name\n",
      "batch\n",
      "layer2.0.bn2.inference\n",
      "False\n",
      "layer2.0.se.fc1.weight\n",
      "(8, 64)\n",
      "layer2.0.se.fc1.bias\n",
      "(8,)\n",
      "layer2.0.se.fc2.weight\n",
      "(64, 8)\n",
      "layer2.0.se.fc2.bias\n",
      "(64,)\n",
      "layer2.0.downsample.layers.0.weight\n",
      "(64, 32, 1, 1)\n",
      "layer2.0.downsample.layers.1.weight\n",
      "(64,)\n",
      "layer2.0.downsample.layers.1.bias\n",
      "(64,)\n",
      "layer2.0.downsample.layers.1.axis_name\n",
      "batch\n",
      "layer2.0.downsample.layers.1.inference\n",
      "False\n",
      "layer2.1.conv1.weight\n",
      "(64, 64, 3, 3)\n",
      "layer2.1.conv2.weight\n",
      "(64, 64, 3, 3)\n",
      "layer2.1.bn1.weight\n",
      "(64,)\n",
      "layer2.1.bn1.bias\n",
      "(64,)\n",
      "layer2.1.bn1.axis_name\n",
      "batch\n",
      "layer2.1.bn1.inference\n",
      "False\n",
      "layer2.1.bn2.weight\n",
      "(64,)\n",
      "layer2.1.bn2.bias\n",
      "(64,)\n",
      "layer2.1.bn2.axis_name\n",
      "batch\n",
      "layer2.1.bn2.inference\n",
      "False\n",
      "layer2.1.se.fc1.weight\n",
      "(8, 64)\n",
      "layer2.1.se.fc1.bias\n",
      "(8,)\n",
      "layer2.1.se.fc2.weight\n",
      "(64, 8)\n",
      "layer2.1.se.fc2.bias\n",
      "(64,)\n",
      "layer2.2.conv1.weight\n",
      "(64, 64, 3, 3)\n",
      "layer2.2.conv2.weight\n",
      "(64, 64, 3, 3)\n",
      "layer2.2.bn1.weight\n",
      "(64,)\n",
      "layer2.2.bn1.bias\n",
      "(64,)\n",
      "layer2.2.bn1.axis_name\n",
      "batch\n",
      "layer2.2.bn1.inference\n",
      "False\n",
      "layer2.2.bn2.weight\n",
      "(64,)\n",
      "layer2.2.bn2.bias\n",
      "(64,)\n",
      "layer2.2.bn2.axis_name\n",
      "batch\n",
      "layer2.2.bn2.inference\n",
      "False\n",
      "layer2.2.se.fc1.weight\n",
      "(8, 64)\n",
      "layer2.2.se.fc1.bias\n",
      "(8,)\n",
      "layer2.2.se.fc2.weight\n",
      "(64, 8)\n",
      "layer2.2.se.fc2.bias\n",
      "(64,)\n",
      "layer2.3.conv1.weight\n",
      "(64, 64, 3, 3)\n",
      "layer2.3.conv2.weight\n",
      "(64, 64, 3, 3)\n",
      "layer2.3.bn1.weight\n",
      "(64,)\n",
      "layer2.3.bn1.bias\n",
      "(64,)\n",
      "layer2.3.bn1.axis_name\n",
      "batch\n",
      "layer2.3.bn1.inference\n",
      "False\n",
      "layer2.3.bn2.weight\n",
      "(64,)\n",
      "layer2.3.bn2.bias\n",
      "(64,)\n",
      "layer2.3.bn2.axis_name\n",
      "batch\n",
      "layer2.3.bn2.inference\n",
      "False\n",
      "layer2.3.se.fc1.weight\n",
      "(8, 64)\n",
      "layer2.3.se.fc1.bias\n",
      "(8,)\n",
      "layer2.3.se.fc2.weight\n",
      "(64, 8)\n",
      "layer2.3.se.fc2.bias\n",
      "(64,)\n",
      "layer3.0.conv1.weight\n",
      "(128, 64, 3, 3)\n",
      "layer3.0.conv2.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.0.bn1.weight\n",
      "(128,)\n",
      "layer3.0.bn1.bias\n",
      "(128,)\n",
      "layer3.0.bn1.axis_name\n",
      "batch\n",
      "layer3.0.bn1.inference\n",
      "False\n",
      "layer3.0.bn2.weight\n",
      "(128,)\n",
      "layer3.0.bn2.bias\n",
      "(128,)\n",
      "layer3.0.bn2.axis_name\n",
      "batch\n",
      "layer3.0.bn2.inference\n",
      "False\n",
      "layer3.0.se.fc1.weight\n",
      "(16, 128)\n",
      "layer3.0.se.fc1.bias\n",
      "(16,)\n",
      "layer3.0.se.fc2.weight\n",
      "(128, 16)\n",
      "layer3.0.se.fc2.bias\n",
      "(128,)\n",
      "layer3.0.downsample.layers.0.weight\n",
      "(128, 64, 1, 1)\n",
      "layer3.0.downsample.layers.1.weight\n",
      "(128,)\n",
      "layer3.0.downsample.layers.1.bias\n",
      "(128,)\n",
      "layer3.0.downsample.layers.1.axis_name\n",
      "batch\n",
      "layer3.0.downsample.layers.1.inference\n",
      "False\n",
      "layer3.1.conv1.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.1.conv2.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.1.bn1.weight\n",
      "(128,)\n",
      "layer3.1.bn1.bias\n",
      "(128,)\n",
      "layer3.1.bn1.axis_name\n",
      "batch\n",
      "layer3.1.bn1.inference\n",
      "False\n",
      "layer3.1.bn2.weight\n",
      "(128,)\n",
      "layer3.1.bn2.bias\n",
      "(128,)\n",
      "layer3.1.bn2.axis_name\n",
      "batch\n",
      "layer3.1.bn2.inference\n",
      "False\n",
      "layer3.1.se.fc1.weight\n",
      "(16, 128)\n",
      "layer3.1.se.fc1.bias\n",
      "(16,)\n",
      "layer3.1.se.fc2.weight\n",
      "(128, 16)\n",
      "layer3.1.se.fc2.bias\n",
      "(128,)\n",
      "layer3.2.conv1.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.2.conv2.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.2.bn1.weight\n",
      "(128,)\n",
      "layer3.2.bn1.bias\n",
      "(128,)\n",
      "layer3.2.bn1.axis_name\n",
      "batch\n",
      "layer3.2.bn1.inference\n",
      "False\n",
      "layer3.2.bn2.weight\n",
      "(128,)\n",
      "layer3.2.bn2.bias\n",
      "(128,)\n",
      "layer3.2.bn2.axis_name\n",
      "batch\n",
      "layer3.2.bn2.inference\n",
      "False\n",
      "layer3.2.se.fc1.weight\n",
      "(16, 128)\n",
      "layer3.2.se.fc1.bias\n",
      "(16,)\n",
      "layer3.2.se.fc2.weight\n",
      "(128, 16)\n",
      "layer3.2.se.fc2.bias\n",
      "(128,)\n",
      "layer3.3.conv1.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.3.conv2.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.3.bn1.weight\n",
      "(128,)\n",
      "layer3.3.bn1.bias\n",
      "(128,)\n",
      "layer3.3.bn1.axis_name\n",
      "batch\n",
      "layer3.3.bn1.inference\n",
      "False\n",
      "layer3.3.bn2.weight\n",
      "(128,)\n",
      "layer3.3.bn2.bias\n",
      "(128,)\n",
      "layer3.3.bn2.axis_name\n",
      "batch\n",
      "layer3.3.bn2.inference\n",
      "False\n",
      "layer3.3.se.fc1.weight\n",
      "(16, 128)\n",
      "layer3.3.se.fc1.bias\n",
      "(16,)\n",
      "layer3.3.se.fc2.weight\n",
      "(128, 16)\n",
      "layer3.3.se.fc2.bias\n",
      "(128,)\n",
      "layer3.4.conv1.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.4.conv2.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.4.bn1.weight\n",
      "(128,)\n",
      "layer3.4.bn1.bias\n",
      "(128,)\n",
      "layer3.4.bn1.axis_name\n",
      "batch\n",
      "layer3.4.bn1.inference\n",
      "False\n",
      "layer3.4.bn2.weight\n",
      "(128,)\n",
      "layer3.4.bn2.bias\n",
      "(128,)\n",
      "layer3.4.bn2.axis_name\n",
      "batch\n",
      "layer3.4.bn2.inference\n",
      "False\n",
      "layer3.4.se.fc1.weight\n",
      "(16, 128)\n",
      "layer3.4.se.fc1.bias\n",
      "(16,)\n",
      "layer3.4.se.fc2.weight\n",
      "(128, 16)\n",
      "layer3.4.se.fc2.bias\n",
      "(128,)\n",
      "layer3.5.conv1.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.5.conv2.weight\n",
      "(128, 128, 3, 3)\n",
      "layer3.5.bn1.weight\n",
      "(128,)\n",
      "layer3.5.bn1.bias\n",
      "(128,)\n",
      "layer3.5.bn1.axis_name\n",
      "batch\n",
      "layer3.5.bn1.inference\n",
      "False\n",
      "layer3.5.bn2.weight\n",
      "(128,)\n",
      "layer3.5.bn2.bias\n",
      "(128,)\n",
      "layer3.5.bn2.axis_name\n",
      "batch\n",
      "layer3.5.bn2.inference\n",
      "False\n",
      "layer3.5.se.fc1.weight\n",
      "(16, 128)\n",
      "layer3.5.se.fc1.bias\n",
      "(16,)\n",
      "layer3.5.se.fc2.weight\n",
      "(128, 16)\n",
      "layer3.5.se.fc2.bias\n",
      "(128,)\n",
      "layer4.0.conv1.weight\n",
      "(256, 128, 3, 3)\n",
      "layer4.0.conv2.weight\n",
      "(256, 256, 3, 3)\n",
      "layer4.0.bn1.weight\n",
      "(256,)\n",
      "layer4.0.bn1.bias\n",
      "(256,)\n",
      "layer4.0.bn1.axis_name\n",
      "batch\n",
      "layer4.0.bn1.inference\n",
      "False\n",
      "layer4.0.bn2.weight\n",
      "(256,)\n",
      "layer4.0.bn2.bias\n",
      "(256,)\n",
      "layer4.0.bn2.axis_name\n",
      "batch\n",
      "layer4.0.bn2.inference\n",
      "False\n",
      "layer4.0.se.fc1.weight\n",
      "(32, 256)\n",
      "layer4.0.se.fc1.bias\n",
      "(32,)\n",
      "layer4.0.se.fc2.weight\n",
      "(256, 32)\n",
      "layer4.0.se.fc2.bias\n",
      "(256,)\n",
      "layer4.0.downsample.layers.0.weight\n",
      "(256, 128, 1, 1)\n",
      "layer4.0.downsample.layers.1.weight\n",
      "(256,)\n",
      "layer4.0.downsample.layers.1.bias\n",
      "(256,)\n",
      "layer4.0.downsample.layers.1.axis_name\n",
      "batch\n",
      "layer4.0.downsample.layers.1.inference\n",
      "False\n",
      "layer4.1.conv1.weight\n",
      "(256, 256, 3, 3)\n",
      "layer4.1.conv2.weight\n",
      "(256, 256, 3, 3)\n",
      "layer4.1.bn1.weight\n",
      "(256,)\n",
      "layer4.1.bn1.bias\n",
      "(256,)\n",
      "layer4.1.bn1.axis_name\n",
      "batch\n",
      "layer4.1.bn1.inference\n",
      "False\n",
      "layer4.1.bn2.weight\n",
      "(256,)\n",
      "layer4.1.bn2.bias\n",
      "(256,)\n",
      "layer4.1.bn2.axis_name\n",
      "batch\n",
      "layer4.1.bn2.inference\n",
      "False\n",
      "layer4.1.se.fc1.weight\n",
      "(32, 256)\n",
      "layer4.1.se.fc1.bias\n",
      "(32,)\n",
      "layer4.1.se.fc2.weight\n",
      "(256, 32)\n",
      "layer4.1.se.fc2.bias\n",
      "(256,)\n",
      "layer4.2.conv1.weight\n",
      "(256, 256, 3, 3)\n",
      "layer4.2.conv2.weight\n",
      "(256, 256, 3, 3)\n",
      "layer4.2.bn1.weight\n",
      "(256,)\n",
      "layer4.2.bn1.bias\n",
      "(256,)\n",
      "layer4.2.bn1.axis_name\n",
      "batch\n",
      "layer4.2.bn1.inference\n",
      "False\n",
      "layer4.2.bn2.weight\n",
      "(256,)\n",
      "layer4.2.bn2.bias\n",
      "(256,)\n",
      "layer4.2.bn2.axis_name\n",
      "batch\n",
      "layer4.2.bn2.inference\n",
      "False\n",
      "layer4.2.se.fc1.weight\n",
      "(32, 256)\n",
      "layer4.2.se.fc1.bias\n",
      "(32,)\n",
      "layer4.2.se.fc2.weight\n",
      "(256, 32)\n",
      "layer4.2.se.fc2.bias\n",
      "(256,)\n",
      "attention_conv1.weight\n",
      "(128, 2048, 1)\n",
      "attention_conv1.bias\n",
      "(128, 1)\n",
      "attention_batch_norm.weight\n",
      "(128,)\n",
      "attention_batch_norm.bias\n",
      "(128,)\n",
      "attention_batch_norm.axis_name\n",
      "batch\n",
      "attention_batch_norm.inference\n",
      "False\n",
      "attention_conv2.weight\n",
      "(2048, 128, 1)\n",
      "attention_conv2.bias\n",
      "(2048, 1)\n",
      "fc.weight\n",
      "(512, 4096)\n",
      "fc.bias\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "from TTS.tts.layers.xtts.dvae import DiscreteVAE\n",
    "import jax\n",
    "import torch\n",
    "import equinox as eqx\n",
    "import pprint as pp\n",
    "\n",
    "# Exported from .ipynb using python3 export.py (Exports all cells with the export tag)\n",
    "from TTS.tts.layers.xtts.trainer.gpt_trainer import (\n",
    "    GPTArgs,\n",
    "    GPTTrainerConfig,\n",
    "    GPTTrainer,\n",
    "    XttsAudioConfig,\n",
    ")\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "from ResNet_for_XTTS import ResNet\n",
    "\n",
    "# init args and config\n",
    "model_args = GPTArgs(\n",
    "    max_conditioning_length=132300,  # 6 secs\n",
    "    min_conditioning_length=11025,  # 0.5 secs\n",
    "    debug_loading_failures=False,\n",
    "    max_wav_length=255995,  # ~11.6 seconds\n",
    "    max_text_length=200,\n",
    "    mel_norm_file=\"./mel_stats\",\n",
    "    dvae_checkpoint=\"\",\n",
    "    xtts_checkpoint=\"./model.pth\",  # checkpoint path of the model that you want to fine-tune\n",
    "    tokenizer_file=\"\",\n",
    "    gpt_num_audio_tokens=1026,\n",
    "    gpt_start_audio_token=1024,\n",
    "    gpt_stop_audio_token=1025,\n",
    "    gpt_use_masking_gt_prompt_approach=True,\n",
    "    gpt_use_perceiver_resampler=True,\n",
    ")\n",
    "audio_config = XttsAudioConfig(\n",
    "    sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=24000\n",
    ")\n",
    "\n",
    "config = GPTTrainerConfig()\n",
    "\n",
    "config.load_json(\"./config.json\")\n",
    "\n",
    "config.epochs = 1\n",
    "config.model_args = model_args\n",
    "config.audio = audio_config\n",
    "config.num_loader_workers = 8\n",
    "config.eval_split_max_size = 256\n",
    "config.print_step = 50\n",
    "config.plot_step = 100\n",
    "config.log_model_step = 100\n",
    "config.save_n_checkpoints = 1\n",
    "config.save_checkpoints = True\n",
    "config.print_eval = False\n",
    "config.optimizer = \"AdamW\"\n",
    "config.optimizer_params = {\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1}\n",
    "config.test_sentences = []\n",
    "\n",
    "their_resnet = Xtts(config).hifigan_decoder.speaker_encoder\n",
    "# init the model from config\n",
    "\n",
    "# Take all the params for the torch model. Print them and map them to our model.\n",
    "\n",
    "torch_params = {\n",
    "    name: param.detach().numpy() for name, param in their_resnet.named_parameters()\n",
    "}\n",
    "\n",
    "# for x in torch_params:\n",
    "#     print(x)\n",
    "#     print(torch_params[x].shape)\n",
    "# # print(v)\n",
    "\n",
    "\n",
    "def boop(path, a):\n",
    "    seq = [str(p).strip(\"[].\") for p in path]\n",
    "    print(\".\".join(seq))\n",
    "    try:\n",
    "        print(a.shape)\n",
    "    except:\n",
    "        print(a)\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(2)\n",
    "\n",
    "our_resnet, state = eqx.nn.make_with_state(ResNet)(64, 512, key=key)\n",
    "test = jax.tree_util.tree_map_with_path(lambda x, a: boop(x, a), our_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_to_jax_keys = {\n",
    "    (\"batch_norm.weight\", \"bn1.weight\"),\n",
    "    (\"batch_norm.bias\", \"bn1.bias\"),\n",
    "    (\"attention_conv1.bias\", \"attention.0.bias\"),\n",
    "    (\"attention_conv1.weight\", \"attention.0.weight\"),\n",
    "    (\"attention_batch_norm.bias\", \"attention.2.bias\"),\n",
    "    (\"attention_batch_norm.weight\", \"attention.2.weight\"),\n",
    "    (\"attention_conv2.bias\", \"attention.3.bias\"),\n",
    "    (\"attention_conv2.weight\", \"attention.3.weight\"),\n",
    "}\n",
    "\n",
    "\n",
    "# Function to update the JAX model parameters\n",
    "def update_params(path, x):\n",
    "    seq = [str(p).strip(\"[].\") for p in path]\n",
    "    # print(seq)\n",
    "    stri = \".\".join(seq)\n",
    "    for jax_key, torch_key in torch_to_jax_keys:\n",
    "        if jax_key == stri:\n",
    "            if \"batch_norm\" in stri:\n",
    "                return jax.numpy.array(torch_params[torch_key])\n",
    "            if \"bias\" in jax_key:\n",
    "                return jax.numpy.expand_dims(torch_params[torch_key], -1)\n",
    "            return jax.numpy.array(torch_params[torch_key])\n",
    "    if stri in torch_params.keys():\n",
    "        if \"bias\" in seq:\n",
    "            # if \"fc.bias\" == stri:\n",
    "            #     return jax.numpy.array(torch_params[stri])\n",
    "            if \"conv1\" in seq:\n",
    "                return jax.numpy.expand_dims(\n",
    "                    jax.numpy.expand_dims(torch_params[stri], -1), -1\n",
    "                )\n",
    "            return jax.numpy.array(torch_params[stri])\n",
    "        if \"fc\" in stri:\n",
    "            return jax.numpy.array(torch_params[stri])\n",
    "        return jax.numpy.array(torch_params[stri])\n",
    "    if len(seq) <= 2:\n",
    "        return x\n",
    "    if \"fc1\" in seq[3]:\n",
    "        if seq[-1] == \"weight\":\n",
    "            return jax.numpy.array(\n",
    "                torch_params[\n",
    "                    \".\".join(\n",
    "                        [\n",
    "                            seq[0],\n",
    "                            seq[1],\n",
    "                            seq[2],\n",
    "                            \"fc.0\",\n",
    "                            \"weight\",\n",
    "                        ]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        elif seq[-1] == \"bias\":\n",
    "            return jax.numpy.array(\n",
    "                torch_params[\n",
    "                    \".\".join(\n",
    "                        [\n",
    "                            seq[0],\n",
    "                            seq[1],\n",
    "                            seq[2],\n",
    "                            \"fc.0\",\n",
    "                            \"bias\",\n",
    "                        ]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "    if \"fc2\" in seq[3]:\n",
    "        if seq[-1] == \"weight\":\n",
    "            return jax.numpy.array(\n",
    "                torch_params[\n",
    "                    \".\".join(\n",
    "                        [\n",
    "                            seq[0],\n",
    "                            seq[1],\n",
    "                            seq[2],\n",
    "                            \"fc.2\",\n",
    "                            \"weight\",\n",
    "                        ]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        elif seq[-1] == \"bias\":\n",
    "            return jax.numpy.array(\n",
    "                torch_params[\n",
    "                    \".\".join(\n",
    "                        [\n",
    "                            seq[0],\n",
    "                            seq[1],\n",
    "                            seq[2],\n",
    "                            \"fc.2\",\n",
    "                            \"bias\",\n",
    "                        ]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "    if seq[2] == \"downsample\":\n",
    "        if seq[-1] == \"weight\":\n",
    "            return jax.numpy.array(\n",
    "                torch_params[\n",
    "                    \".\".join(\n",
    "                        [\n",
    "                            seq[0],\n",
    "                            seq[1],\n",
    "                            seq[2],\n",
    "                            seq[4],\n",
    "                            \"weight\",\n",
    "                        ]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        elif seq[-1] == \"bias\":\n",
    "            return jax.numpy.array(\n",
    "                torch_params[\n",
    "                    \".\".join(\n",
    "                        [\n",
    "                            seq[0],\n",
    "                            seq[1],\n",
    "                            seq[2],\n",
    "                            seq[4],\n",
    "                            \"bias\",\n",
    "                        ]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "    return x\n",
    "\n",
    "\n",
    "# Grab the checky ones that don't have a name but that we need\n",
    "# torch_params[\"dvae.codebook.embed\"] = dvae.codebook.embed\n",
    "# dvae.load_state_dict(torch.load(dvae_pretrained), strict=False)\n",
    "# print(list(dvae.decoder.state_dict()))\n",
    "# Updatorche the JAX model parameters\n",
    "our_resnet = jax.tree_util.tree_map_with_path(update_params, our_resnet)\n",
    "\n",
    "eqx.tree_serialise_leaves(\"./xttsresnet.eqx\", our_resnet)\n",
    "# Replace the encoder in the model with the updated encoder\n",
    "# model = eqx.tree_at(lambda m: m, model, model)\n",
    "# print(model.quantizer.codebook.shape)\n",
    "# eqx.tree_serialise_leaves(\"./xttsvqvae.eqx\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are chaotic tests I made to check things worked, progressively going through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor([[[9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07],\n",
      "         [9.5367e-07, 9.5367e-07, 9.5367e-07, 9.5367e-07]]])\n",
      "(1, 64, 4)\n",
      "1.0\n",
      "1.0\n",
      "[[[9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]\n",
      "  [9.5367386e-07 9.5367386e-07 9.5367386e-07 9.5367386e-07]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import jax\n",
    "\n",
    "x = torch.ones((1, 64, 4))\n",
    "x1 = jax.numpy.array(x.numpy())\n",
    "\n",
    "# their_resnet = their_resnet.eval()\n",
    "# their_resnet = Xtts(config).hifigan_decoder.speaker_encoder\n",
    "our_resnet, state = eqx.nn.make_with_state(ResNet)(64, 1, key=key)\n",
    "our_resnet = jax.tree_util.tree_map_with_path(update_params, our_resnet)\n",
    "# our_resnet = eqx.nn.inference_mode(our_resnet)\n",
    "\n",
    "torch.testing.assert_close(x, torch.from_numpy(np.array(x1)))\n",
    "# For the possible audio input instaed of mel\n",
    "y = x.squeeze_(1)\n",
    "print(y.min())\n",
    "\n",
    "y = (y + 1e-6).log()\n",
    "print(y)\n",
    "# y = their_resnet.instancenorm(y).unsqueeze(1)\n",
    "# y = their_resnet.conv1(y)\n",
    "# y = their_resnet.relu(y)\n",
    "# y = their_resnet.bn1(y)\n",
    "# y = their_resnet.layer1(y)\n",
    "# y = their_resnet.layer2(y)\n",
    "# y = their_resnet.layer3(y)\n",
    "# y = their_resnet.layer4(y)\n",
    "# y += their_resnet.layer1[0].downsample(y)\n",
    "\n",
    "# y = their_resnet.layer1[0].se(y)\n",
    "print(x1.shape)\n",
    "print(np.min(x1))\n",
    "x1 = jax.lax.clamp(min=float(0), x=x1, max=jax.numpy.inf)\n",
    "print(np.min(x1))\n",
    "\n",
    "y1 = jax.numpy.log(x1 + 1e-6)\n",
    "print(y1)\n",
    "# y1 = jax.vmap(eqx.nn.GroupNorm(64, 64, channelwise_affine=False))(y1)\n",
    "# y1 = jax.numpy.expand_dims(y1, 1)\n",
    "# print(y1.shape)\n",
    "# y1 = jax.vmap(our_resnet.conv1)(y1)\n",
    "# print(y1.shape)\n",
    "# y1 = jax.nn.relu(y1)\n",
    "# y1, state = jax.vmap(\n",
    "#     our_resnet.batch_norm, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "# )(y1, state)\n",
    "# for layer in our_resnet.layer1:\n",
    "#     y1, state = jax.vmap(\n",
    "#         layer, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "#     )(y1, state)\n",
    "# for layer in our_resnet.layer2:\n",
    "#     y1, state = jax.vmap(\n",
    "#         layer, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "#     )(y1, state)\n",
    "# for layer in our_resnet.layer3:\n",
    "#     y1, state = jax.vmap(\n",
    "#         layer, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "#     )(y1, state)\n",
    "# for layer in our_resnet.layer4:\n",
    "#     y1, state = jax.vmap(\n",
    "#         layer, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "#     )(y1, state)\n",
    "# y1 = jax.vmap(our_resnet.layer1[0].conv1)(z1)\n",
    "# y1 = jax.nn.relu(y1)\n",
    "# y1, state = jax.vmap(\n",
    "#     our_resnet.layer1[0].bn1, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "# )(y1, state)\n",
    "# y1 = jax.vmap(our_resnet.layer1[0].conv2)(y1)\n",
    "# y1, state = jax.vmap(\n",
    "#     our_resnet.layer1[0].bn2, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "# )(y1, state)\n",
    "# y1 = jax.vmap(our_resnet.layer1[0].se)(y1)\n",
    "# # y1 += jax.vmap(our_resnet.layer1[0].downsample)(y1)\n",
    "# y1 += z1\n",
    "# y1 = jax.nn.relu(y1)\n",
    "\n",
    "# def mul(x, y):\n",
    "#     return x * y\n",
    "\n",
    "\n",
    "# y1 = jax.vmap(mul)(z, y1)\n",
    "# y1 = jax.vmap(our_resnet.layer1[0].se.)\n",
    "# y1 = jax.vmap(our_resnet.layer1[0].se)(y1)\n",
    "\n",
    "\n",
    "torch.testing.assert_close(y, torch.from_numpy(np.array(y1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there still is a difference, it's low enough that we musn't waste too much time on it. I suspect it comes from the bias at the last layer conv..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048, 2])\n",
      "torch.Size([1, 2048, 2])\n",
      "torch.Size([1, 512])\n",
      "(4096,)\n",
      "(512, 4096)\n",
      "(1, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import jax\n",
    "\n",
    "x = torch.randn((1, 256, 8, 2))\n",
    "y = jax.numpy.array(x.numpy())[0]\n",
    "\n",
    "# their_resnet = their_resnet.eval()\n",
    "# their_resnet = Xtts(config).hifigan_decoder.speaker_encoder\n",
    "our_resnet, state = eqx.nn.make_with_state(ResNet)(64, 512, key=key)\n",
    "our_resnet = jax.tree_util.tree_map_with_path(update_params, our_resnet)\n",
    "\n",
    "x = x.reshape(x.size()[0], -1, x.size()[-1])\n",
    "print(x.shape)\n",
    "w = their_resnet.attention(x)\n",
    "print(w.shape)\n",
    "\n",
    "mu = torch.sum(x * w, dim=2)\n",
    "pouet = (torch.sum((x**2) * w, dim=2) - mu**2).clamp(min=1e-5)\n",
    "sg = torch.sqrt(pouet)\n",
    "x = torch.cat((mu, sg), 1)\n",
    "x = their_resnet.fc(x)\n",
    "print(x.shape)\n",
    "y = jax.numpy.reshape(y, (-1, y.shape[-1]))\n",
    "# print(y.shape)\n",
    "\n",
    "# TODO not really justified...\n",
    "v = our_resnet.attention_conv1(y)\n",
    "v = jax.nn.relu(v)\n",
    "v = jax.numpy.expand_dims(v, 0)\n",
    "v, state = jax.vmap(\n",
    "    our_resnet.attention_batch_norm,\n",
    "    axis_name=\"batch\",\n",
    "    in_axes=(0, None),\n",
    "    out_axes=(0, None),\n",
    ")(v, state)\n",
    "v = v[0]\n",
    "v = our_resnet.attention_conv2(v)  # W represents the\n",
    "v = jax.nn.softmax(v, axis=1)\n",
    "mu2 = jax.numpy.sum(y * v, axis=1)\n",
    "pouet2 = jax.lax.clamp(\n",
    "    min=1e-5, x=jax.numpy.sum((y**2) * v, axis=1) - mu2**2, max=jax.numpy.inf\n",
    ")\n",
    "torch.testing.assert_close(pouet, torch.from_numpy(np.array(np.expand_dims(pouet2, 0))))\n",
    "sg2 = jax.numpy.sqrt(pouet2)\n",
    "y = jax.lax.concatenate((mu2, sg2), 0)\n",
    "\n",
    "print(y.shape)\n",
    "print(our_resnet.fc.weight.shape)\n",
    "y = our_resnet.fc(y)\n",
    "y = jax.numpy.expand_dims(y, 0)\n",
    "print(y.shape)\n",
    "\n",
    "torch.testing.assert_close(x, torch.from_numpy(np.array(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 251 / 512 (49.0%)\nGreatest absolute difference: 4.2222440242767334e-05 at index (0, 459) (up to 1e-05 allowed)\nGreatest relative difference: 0.008624270558357239 at index (0, 387) (up to 1.3e-06 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 84\u001b[0m\n\u001b[1;32m     81\u001b[0m y \u001b[38;5;241m=\u001b[39m our_resnet\u001b[38;5;241m.\u001b[39mfc(y)\n\u001b[1;32m     82\u001b[0m y \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mexpand_dims(y, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/torch/testing/_comparison.py:1530\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1508\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1509\u001b[0m     actual,\n\u001b[1;32m   1510\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1526\u001b[0m )\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 251 / 512 (49.0%)\nGreatest absolute difference: 4.2222440242767334e-05 at index (0, 459) (up to 1e-05 allowed)\nGreatest relative difference: 0.008624270558357239 at index (0, 387) (up to 1.3e-06 allowed)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import jax\n",
    "\n",
    "x = torch.randn((1, 64, 40))\n",
    "x1 = jax.numpy.array(x.numpy())\n",
    "\n",
    "# their_resnet = their_resnet.eval()\n",
    "# their_resnet = Xtts(config).hifigan_decoder.speaker_encoder\n",
    "our_resnet, state = eqx.nn.make_with_state(ResNet)(64, 1, key=key)\n",
    "our_resnet = jax.tree_util.tree_map_with_path(update_params, our_resnet)\n",
    "# our_resnet = eqx.nn.inference_mode(our_resnet)\n",
    "\n",
    "torch.testing.assert_close(x, torch.from_numpy(np.array(x1)))\n",
    "# For the possible audio input instaed of mel\n",
    "y = x.squeeze_(1)\n",
    "y = their_resnet.instancenorm(y).unsqueeze(1)\n",
    "y = their_resnet.conv1(y)\n",
    "y = their_resnet.relu(y)\n",
    "y = their_resnet.bn1(y)\n",
    "y = their_resnet.layer1(y)\n",
    "y = their_resnet.layer2(y)\n",
    "y = their_resnet.layer3(y)\n",
    "x = their_resnet.layer4(y)\n",
    "x = x.reshape(x.size()[0], -1, x.size()[-1])\n",
    "w = their_resnet.attention(x)\n",
    "\n",
    "mu = torch.sum(x * w, dim=2)\n",
    "sg = torch.sqrt((torch.sum((x**2) * w, dim=2) - mu**2).clamp(min=1e-5))\n",
    "x = torch.cat((mu, sg), 1)\n",
    "x = their_resnet.fc(x)\n",
    "# y += their_resnet.layer1[0].downsample(y)\n",
    "\n",
    "# y = their_resnet.layer1[0].se(y)\n",
    "y1 = jax.vmap(eqx.nn.GroupNorm(64, 64, channelwise_affine=False))(x1)\n",
    "y1 = jax.numpy.expand_dims(y1, 1)\n",
    "y1 = jax.vmap(our_resnet.conv1)(y1)\n",
    "y1 = jax.nn.relu(y1)\n",
    "y1, state = jax.vmap(\n",
    "    our_resnet.batch_norm, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    ")(y1, state)\n",
    "for layer in our_resnet.layer1:\n",
    "    y1, state = jax.vmap(\n",
    "        layer, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "    )(y1, state)\n",
    "for layer in our_resnet.layer2:\n",
    "    y1, state = jax.vmap(\n",
    "        layer, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "    )(y1, state)\n",
    "for layer in our_resnet.layer3:\n",
    "    y1, state = jax.vmap(\n",
    "        layer, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "    )(y1, state)\n",
    "for layer in our_resnet.layer4:\n",
    "    y1, state = jax.vmap(\n",
    "        layer, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "    )(y1, state)\n",
    "\n",
    "y = y1\n",
    "y = jax.numpy.reshape(y, (-1, y.shape[-1]))\n",
    "v = our_resnet.attention_conv1(y)\n",
    "v = jax.nn.relu(v)\n",
    "v = jax.numpy.expand_dims(v, 0)\n",
    "v, state = jax.vmap(\n",
    "    our_resnet.attention_batch_norm,\n",
    "    axis_name=\"batch\",\n",
    "    in_axes=(0, None),\n",
    "    out_axes=(0, None),\n",
    ")(v, state)\n",
    "v = v[0]\n",
    "v = our_resnet.attention_conv2(v)  # W represents the\n",
    "v = jax.nn.softmax(v, axis=1)\n",
    "mu2 = jax.numpy.sum(y * v, axis=1)\n",
    "sg2 = jax.numpy.sqrt(\n",
    "    jax.lax.clamp(\n",
    "        min=1e-5, x=jax.numpy.sum((y**2) * v, axis=1) - mu2**2, max=jax.numpy.inf\n",
    "    )\n",
    ")\n",
    "y = jax.lax.concatenate((mu2, sg2), 0)\n",
    "\n",
    "y = our_resnet.fc(y)\n",
    "y = jax.numpy.expand_dims(y, 0)\n",
    "\n",
    "torch.testing.assert_close(x, torch.from_numpy(np.array(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "their_resnet.log_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import jax\n",
    "\n",
    "x = torch.randn((1, 256, 8, 2))\n",
    "y = jax.numpy.array(x.numpy())[0]\n",
    "our_resnet, state = eqx.nn.make_with_state(ResNet)(64, 512, key=key)\n",
    "our_resnet = jax.tree_util.tree_map_with_path(update_params, our_resnet)\n",
    "\n",
    "x = x.reshape(x.size()[0], -1, x.size()[-1])\n",
    "\n",
    "w = their_resnet.attention(x)\n",
    "\n",
    "if their_resnet.encoder_type == \"SAP\":\n",
    "    x = torch.sum(x * w, dim=2)\n",
    "elif their_resnet.encoder_type == \"ASP\":\n",
    "    mu = torch.sum(x * w, dim=2)\n",
    "    sg = torch.sqrt((torch.sum((x**2) * w, dim=2) - mu**2).clamp(min=1e-5))\n",
    "    x = torch.cat((mu, sg), 1)\n",
    "\n",
    "x = x.view(x.size()[0], -1)\n",
    "x = their_resnet.fc(x)\n",
    "\n",
    "y = jax.numpy.reshape(y, (-1, y.shape[-1]))\n",
    "# TODO not really justified...\n",
    "w = our_resnet.attention_conv1(y)\n",
    "w = jax.nn.relu(w)\n",
    "w = np.expand_dims(w, 0)\n",
    "w, state = jax.vmap(\n",
    "    our_resnet.attention_batch_norm,\n",
    "    axis_name=\"batch\",\n",
    "    in_axes=(0, None),\n",
    "    out_axes=(0, None),\n",
    ")(w, state)\n",
    "w = w[0]\n",
    "w = our_resnet.attention_conv2(w)  # W represents the\n",
    "w = jax.nn.softmax(w, axis=1)\n",
    "\n",
    "mu = jax.numpy.sum(y * w, axis=1)\n",
    "sg = jax.lax.clamp(\n",
    "    min=1e-5,\n",
    "    x=jax.numpy.sum((y**2) * w, axis=1) - mu**2,\n",
    "    max=jax.numpy.float32(10),\n",
    ")\n",
    "sg = jax.numpy.sqrt(sg)\n",
    "\n",
    "y = jax.lax.concatenate((mu, sg), 0)\n",
    "\n",
    "y = our_resnet.fc(y)\n",
    "\n",
    "y = np.expand_dims(y, 0)\n",
    "\n",
    "torch.testing.assert_close(x, torch.from_numpy(np.array(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 15 / 512 (2.9%)\nGreatest absolute difference: 1.329183578491211e-05 at index (0, 472) (up to 1e-05 allowed)\nGreatest relative difference: 0.0002463693672325462 at index (0, 183) (up to 1.3e-06 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m y1, state \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\n\u001b[1;32m     17\u001b[0m     our_resnet, axis_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), out_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m )(x1, state)\n\u001b[1;32m     19\u001b[0m y1 \u001b[38;5;241m=\u001b[39m y1\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/torch/testing/_comparison.py:1530\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1508\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1509\u001b[0m     actual,\n\u001b[1;32m   1510\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1526\u001b[0m )\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 15 / 512 (2.9%)\nGreatest absolute difference: 1.329183578491211e-05 at index (0, 472) (up to 1e-05 allowed)\nGreatest relative difference: 0.0002463693672325462 at index (0, 183) (up to 1.3e-06 allowed)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import jax\n",
    "\n",
    "# x = torch.randn((1, 256, 8, 2))\n",
    "x = torch.randn((1, 64, 80))\n",
    "x1 = jax.numpy.array(x.numpy())\n",
    "\n",
    "our_resnet, state = eqx.nn.make_with_state(ResNet)(64, 512, key=key)\n",
    "our_resnet = jax.tree_util.tree_map_with_path(update_params, our_resnet)\n",
    "\n",
    "their_resnet.log_input = False\n",
    "their_resnet.use_torch_spec = False\n",
    "y = their_resnet(x)\n",
    "x1 = jax.numpy.expand_dims(x1, 0)\n",
    "y1, state = jax.vmap(\n",
    "    our_resnet, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    ")(x1, state)\n",
    "y1 = y1\n",
    "torch.testing.assert_close(y, torch.from_numpy(np.array(y1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Deserialised leaf at path (GetAttrKey(name='layer1'), SequenceKey(idx=0), GetAttrKey(name='bn1'), GetAttrKey(name='bias')) has changed shape from (32,) in `like` to (32, 1) on disk.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mResNet_for_XTTS\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResNet\n\u001b[1;32m      4\u001b[0m model, state \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mmake_with_state(ResNet)(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m512\u001b[39m, key\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43meqx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_deserialise_leaves\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./xttsresnet.eqx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/equinox/_serialisation.py:333\u001b[0m, in \u001b[0;36mtree_deserialise_leaves\u001b[0;34m(path_or_file, like, filter_spec, is_leaf)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mensure_compile_time_eval():\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# ArrayImpl isn't a public type, so this is how we get access to it instead.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;66;03m# `ensure_compile_time_eval` just in case someone is doing deserialisation\u001b[39;00m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# inside JIT. Which would be weird, but still.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     array_impl_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(jnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 333\u001b[0m \u001b[43mjtu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map_with_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_assert_same\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_impl_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlike\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/jax/_src/tree_util.py:1200\u001b[0m, in \u001b[0;36mtree_map_with_path\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m   1198\u001b[0m keypath_leaves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mkeypath_leaves))\n\u001b[1;32m   1199\u001b[0m all_keypath_leaves \u001b[38;5;241m=\u001b[39m keypath_leaves \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m-> 1200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_keypath_leaves\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/jax/_src/tree_util.py:1200\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1198\u001b[0m keypath_leaves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mkeypath_leaves))\n\u001b[1;32m   1199\u001b[0m all_keypath_leaves \u001b[38;5;241m=\u001b[39m keypath_leaves \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m-> 1200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_keypath_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/equinox/_serialisation.py:178\u001b[0m, in \u001b[0;36m_assert_same.<locals>._assert_same_impl\u001b[0;34m(path, new, old)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new, (np\u001b[38;5;241m.\u001b[39mndarray, jax\u001b[38;5;241m.\u001b[39mArray)):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m old\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeserialised leaf at path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has changed shape from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in `like` to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on disk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m         )\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m old\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeserialised leaf at path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has changed dtype from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in `like` to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on disk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Deserialised leaf at path (GetAttrKey(name='layer1'), SequenceKey(idx=0), GetAttrKey(name='bn1'), GetAttrKey(name='bias')) has changed shape from (32,) in `like` to (32, 1) on disk."
     ]
    }
   ],
   "source": [
    "from ResNet_for_XTTS import ResNet\n",
    "\n",
    "\n",
    "model, state = eqx.nn.make_with_state(ResNet)(64, 512, key=jax.random.PRNGKey(1))\n",
    "\n",
    "model = eqx.tree_deserialise_leaves(\"./xttsresnet.eqx\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
