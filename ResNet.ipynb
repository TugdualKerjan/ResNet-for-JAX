{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Implementing a ResNet34 in JAX for fun âœ¨\"\n",
    "author:\n",
    "  - name: \"Tugdual Kerjan\"\n",
    "    url: https://tugdual.fr\n",
    "    email: tkerjan@outlook.com\n",
    "date: \"November 9, 2024\"\n",
    "number-sections: true\n",
    "reference-location: margin\n",
    "toc: true\n",
    "format: \n",
    "  html:\n",
    "    standalone: true\n",
    "    embed-resources: true\n",
    "    self-contained-math: true\n",
    "    code-fold: false\n",
    "    code-tools: true\n",
    "execute:\n",
    "  output:\n",
    "    false\n",
    "bibliography: assets/bib.bibtex\n",
    "theme: united\n",
    "github: \"https://github.com/TugdualKerjan/ResNet-for-JAX\"\n",
    "lightbox: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the full project, visit the [GitHub repository](https://github.com/TugdualKerjan/ResNet-for-JAX).\n",
    "\n",
    "# Context ðŸ‘€\n",
    "\n",
    "I'm trying to rewrite XTTS in JAX to understand how it works. \n",
    "\n",
    "\n",
    "We are going to implement ResNet, first mentionned in [@he2015deepresiduallearningimage]. This is used as part of a Text to Speech model written by the defunct Coqai company [@casanova2024xttsmassivelymultilingualzeroshot]. The goal of this model is to take in speech, which gives information about the voice of the person we're trying to reproduce, and output some latent representation that will condition HiFiGAN, the model that takes in a high level representation of mumbo jumbo from the GPT2 and spits out Audio ! ResNet is relatively straight forward, it's:\n",
    "\n",
    "::: {.column-margin}\n",
    "\n",
    "![A high level overview of a ResNet from [@dumakude2023automated_image]](assets/encode.png)\n",
    "\n",
    ":::\n",
    "\n",
    "__A lot of convolutional layers__\n",
    "\n",
    "The first layer would look for dots that compose a line, the second for lines that compose a shape, the third for a series of shapes that compose a face... Basically these can be seen as layers of abstraction !\n",
    "\n",
    "__Residual networks__\n",
    "\n",
    "Residual networks mean taking the input and feeding it to the output. What the network has left to interpret would be the residual, i.e. the \"rest\". This also allows the network to set the weights of that layer to 0 if it considers that this added layer isn't necessary !\n",
    "\n",
    "![Image showing a possible configuration where the input is passed to the output [@he2015deepresiduallearningimage]](assets/res.png)\n",
    "\n",
    "__Squeeze and Excite__\n",
    "\n",
    "The ResNet we're implenting here has been spiced up as it also uses sqeeze and excite modules [@hu2019squeezeandexcitationnetworks] to exchange information between \"channels\" (think red green and blue in images for example). This allows more context to be shared in the network for better abstraction of what's really important !\n",
    "\n",
    " ![Image showing how the Squeeze and Excite adds information [@hu2019squeezeandexcitationnetworks]](assets/se.png)\n",
    "\n",
    "# Goal ðŸŽ¯\n",
    "\n",
    "Get a ResNet that can classify MNIST data as a proof that it works !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "We code from bottom to top: First the Squeeze and Excite layer, then the Residual 'block' it's a part of, and finally the various layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing our favorite libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import equinox.nn as nn\n",
    "import typing as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEBlock\n",
    "\n",
    "We start by implementing the Sqeeze and Excite layer. A good explanation for this is provided here : https://amaarora.github.io/fastexplain/2020/07/24/SeNet.html\n",
    "\n",
    "This excerpt might help to make more sense of this:\n",
    "\n",
    "    We expect the learning of convolutional features to be enhanced by explicitly modelling channel interdependencies, so that the network is able to increase its sensitivity to informative features which can be exploited by subsequent transformations. Consequently, we would like to provide it with access to global information and recalibrate filter responses in two steps, squeeze and excitation, before they are fed into the next transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "\n",
    "\n",
    "class SELayer(eqx.Module):\n",
    "    fc1: eqx.nn.Linear\n",
    "    fc2: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, channel, reduction=8, key=None):\n",
    "        key1, key2 = jax.random.split(key, 2)\n",
    "        self.fc1 = eqx.nn.Linear(channel, channel // reduction, use_bias=True, key=key1)\n",
    "        self.fc2 = eqx.nn.Linear(channel // reduction, channel, use_bias=True, key=key2)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = eqx.nn.AdaptiveAvgPool2d(1)(x)\n",
    "        y = jax.numpy.squeeze(y)\n",
    "        y = self.fc1(y)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = jax.nn.sigmoid(y)\n",
    "        y = jax.numpy.expand_dims(y, (1, 2))\n",
    "\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test that this works correctly with some quick code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define PyTorch version of SELayer\n",
    "class SELayerTorch(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super(SELayerTorch, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x32af17f10>\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 1599 / 1600 (99.9%)\nGreatest absolute difference: 0.17174112796783447 at index (0, 39, 0, 1) (up to 1e-05 allowed)\nGreatest relative difference: 0.20674952864646912 at index (0, 43, 0, 0) (up to 1.3e-06 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(res_torch\u001b[38;5;241m.\u001b[39mtype)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print(res[0,0,0,0])\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# print(res_torch[0,0,0,0])\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/torch/testing/_comparison.py:1530\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1508\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1509\u001b[0m     actual,\n\u001b[1;32m   1510\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1526\u001b[0m )\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 1599 / 1600 (99.9%)\nGreatest absolute difference: 0.17174112796783447 at index (0, 39, 0, 1) (up to 1e-05 allowed)\nGreatest relative difference: 0.20674952864646912 at index (0, 43, 0, 0) (up to 1.3e-06 allowed)"
     ]
    }
   ],
   "source": [
    "# | code-fold: true\n",
    "import jax\n",
    "import torch\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "@jax.grad\n",
    "# @jax.jit\n",
    "def loss(model, x, y):\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    return jax.numpy.mean((y - pred_y) ** 2)  # L2 Loss\n",
    "\n",
    "\n",
    "# loss = jax.grad(loss)\n",
    "\n",
    "x_key, y_key, model_key = jax.random.split(jax.random.PRNGKey(0), 3)\n",
    "# Example data\n",
    "x = jax.random.normal(x_key, (1, 100, 4, 4))\n",
    "y = jax.random.normal(y_key, (1, 100))\n",
    "\n",
    "tor = SELayerTorch(100, reduction=2)\n",
    "model = SELayer(100, reduction=2, key=model_key)\n",
    "\n",
    "res_torch = tor(torch.from_numpy(numpy.array(x)))\n",
    "res = jax.vmap(model)(x)\n",
    "# res = torch.from_numpy(numpy.array(res))\n",
    "# print(res_torch.type)\n",
    "# # print(res[0,0,0,0])\n",
    "# # print(res_torch[0,0,0,0])\n",
    "\n",
    "# assert torch.testing.assert_close(res_torch, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResBlock\n",
    "\n",
    "We can move onto the ResBlock, which uses the SEBlock and implements the concept we saw earlier about Residuals. \n",
    "\n",
    "The current issues with Models is that they fail to approxmiate simple funcitions when sufficiently deep because of **vanishing gradients** and the **curse of dimensionality**. Simple shallow ones function though. So why not skip some layers to match the accuracy of the shallow ones ? Residual blocks can do this easily by setting the weights of a layer to 0 and simply letting the input be passed to the output.\n",
    "\n",
    "::: {.column-margin}\n",
    "\n",
    "![The image we saw previously illustrating the concept of Residual networks](assets/res.png)\n",
    "\n",
    ":::\n",
    "\n",
    "When observing the image on the side we notice that the network can learn the identity function by simply setting $$f(x) = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import equinox as eqx\n",
    "\n",
    "\n",
    "class SEBasicBlock(eqx.Module):\n",
    "    conv1: eqx.nn.Conv2d\n",
    "    conv2: eqx.nn.Conv2d\n",
    "    bn1: eqx.nn.BatchNorm\n",
    "    bn2: eqx.nn.BatchNorm\n",
    "    se: SELayer\n",
    "    downsample: None\n",
    "\n",
    "    def __init__(self, channels_in, channels_out, stride=1, downsample=None, key=None):\n",
    "        key1, key3, key5 = jax.random.split(key, 3)\n",
    "\n",
    "        # TODO Understand why bias isn't added.\n",
    "        # TODO Do we want to have a state or simply do GroupNorm instead ?\n",
    "\n",
    "        self.conv1 = eqx.nn.Conv2d(\n",
    "            channels_in,\n",
    "            channels_out,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            use_bias=False,\n",
    "            key=key1,\n",
    "        )\n",
    "        self.bn1 = eqx.nn.BatchNorm(channels_out, axis_name=\"batch\")\n",
    "        self.conv2 = eqx.nn.Conv2d(\n",
    "            channels_out,\n",
    "            channels_out,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=1,\n",
    "            use_bias=False,\n",
    "            key=key3,\n",
    "        )\n",
    "        self.bn2 = eqx.nn.BatchNorm(channels_out, axis_name=\"batch\")\n",
    "\n",
    "        self.se = SELayer(channels_out, key=key5)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def __call__(self, x, state):\n",
    "        residual = x\n",
    "\n",
    "        y = self.conv1(x)\n",
    "\n",
    "        y = jax.nn.relu(y)\n",
    "        y, state = self.bn1(y, state)\n",
    "\n",
    "        y = self.conv2(y)\n",
    "        y, state = self.bn2(y, state)\n",
    "\n",
    "        y = self.se(y)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual, state = self.downsample(x, state)\n",
    "\n",
    "        y = y + residual  # Residual\n",
    "        y = jax.nn.relu(y)\n",
    "\n",
    "        return y, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "\n",
    "We can now move onto the building of the actual network ! We're going to create ResNet for audio using the SEBasicBlock we created. XTTS bases themselves on [@heo2020clovabaselinevoxcelebspeaker] for the model. In the paper they show how they combine multiple layers to embed an image (Mel spectrogram in our case) into a latent vector.\n",
    "\n",
    "![The layers of the architecture proposed in [@heo2020clovabaselinevoxcelebspeaker]](assets/clove.png)\n",
    "\n",
    "The stride at the first layer is removed compared to ResNet-34. Attentive Statistic Pooling [@Okabe_2018] is used to aggregate temporal frames. The channel-wise __weighted standard deviation__ is calculated in addition to the __weighted mean__. This is based on the results showing that information like this is useful when using attention !\n",
    "\n",
    "Below, we add a create_layer method directly taken from XTTS to help with the initialization process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.tools\n",
    "\n",
    "\n",
    "class ResNet(eqx.Module):\n",
    "    conv1: eqx.nn.Conv2d\n",
    "    batch_norm: eqx.nn.BatchNorm\n",
    "\n",
    "    layer1: list\n",
    "    layer2: list\n",
    "    layer3: list\n",
    "    layer4: list\n",
    "\n",
    "    instance_norm: eqx.nn.GroupNorm\n",
    "\n",
    "    attention_conv1: eqx.nn.Conv1d\n",
    "    attention_batch_norm: eqx.nn.BatchNorm\n",
    "    attention_conv2: eqx.nn.Conv1d\n",
    "\n",
    "    fc: eqx.nn.Linear\n",
    "\n",
    "    def create_layer(self, channels_in, channels_out, layers, stride=1, key=None):\n",
    "\n",
    "        downsample = None\n",
    "        if type(stride) == int or channels_in != channels_out:\n",
    "            key, grab = jax.random.split(key, 2)\n",
    "            downsample = eqx.nn.Sequential(\n",
    "                [\n",
    "                    eqx.nn.Conv2d(\n",
    "                        channels_in,\n",
    "                        channels_out,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        use_bias=False,\n",
    "                        key=grab,\n",
    "                    ),\n",
    "                    eqx.nn.BatchNorm(\n",
    "                        channels_out, axis_name=\"batch\", channelwise_affine=False\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        stack_of_blocks = []\n",
    "        # print(key)\n",
    "        key, grab = jax.random.split(key, 2)\n",
    "\n",
    "        stack_of_blocks.append(\n",
    "            SEBasicBlock(channels_in, channels_out, stride, downsample, key=grab)\n",
    "        )\n",
    "        for _ in range(1, layers):\n",
    "\n",
    "            key, grab = jax.random.split(key, 2)\n",
    "            stack_of_blocks.append(\n",
    "                SEBasicBlock(channels_out, channels_out, stride=1, key=grab)\n",
    "            )\n",
    "\n",
    "        return stack_of_blocks\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dims,\n",
    "        proj_dim,\n",
    "        layers=[3, 4, 6, 3],\n",
    "        num_filters=[32, 64, 128, 256],\n",
    "        key=None,\n",
    "    ):\n",
    "        # he_init = jax.nn.initializers.variance_scaling(scale=2.0, mode=\"fan_out\", distribution=\"truncated_normal\")\n",
    "\n",
    "        key, grab = jax.random.split(key, 2)\n",
    "        # TODO self.conv1 = eqx.nn.Conv2d(1, num_filters[0], key=grab, weight_init=he_init)\n",
    "        self.conv1 = eqx.nn.Conv2d(\n",
    "            1, num_filters[0], kernel_size=3, padding=1, key=grab\n",
    "        )\n",
    "        self.batch_norm = eqx.nn.BatchNorm(\n",
    "            num_filters[0], axis_name=\"batch\", channelwise_affine=False\n",
    "        )\n",
    "\n",
    "        key, key1, key2, key3, key4 = jax.random.split(key, 5)\n",
    "        self.layer1 = self.create_layer(\n",
    "            num_filters[0], num_filters[0], layers[0], key=key2\n",
    "        )\n",
    "        self.layer2 = self.create_layer(\n",
    "            num_filters[0], num_filters[1], layers[1], stride=(2, 2), key=key3\n",
    "        )\n",
    "        self.layer3 = self.create_layer(\n",
    "            num_filters[1], num_filters[2], layers[2], stride=(2, 2), key=key4\n",
    "        )\n",
    "        self.layer4 = self.create_layer(\n",
    "            num_filters[2], num_filters[3], layers[3], stride=(2, 2), key=key1\n",
    "        )\n",
    "\n",
    "        # Instance norm seems to be a specific example of groupnorm.\n",
    "        self.instance_norm = eqx.nn.GroupNorm(1, channelwise_affine=False)\n",
    "\n",
    "        key, key1, key2 = jax.random.split(key, 3)\n",
    "\n",
    "        # Basically a FFN but without needing to deal with the channel dimensions.\n",
    "        # doesn't really explain the lowering of dimensions in the middle though...\n",
    "        current_channel_size = int(num_filters[3] * input_dims / 8)\n",
    "        self.attention_conv1 = eqx.nn.Conv1d(\n",
    "            current_channel_size, 128, kernel_size=1, key=key1\n",
    "        )\n",
    "        self.attention_batch_norm = eqx.nn.BatchNorm(\n",
    "            128, axis_name=\"batch\", channelwise_affine=False\n",
    "        )\n",
    "        self.attention_conv2 = eqx.nn.Conv1d(\n",
    "            128, current_channel_size, kernel_size=1, key=key2\n",
    "        )\n",
    "        # TODO  nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "        # Encoder type is ASP, thus the current dims are B, Input_dim / 8 because of the 4 layers,  * 2 * output of layer4.\n",
    "        self.fc = eqx.nn.Linear(current_channel_size * 2, proj_dim, key=key)\n",
    "\n",
    "    def __call__(self, x, state):\n",
    "        y = x\n",
    "\n",
    "        # We expect a mel spectrogram as input for now.\n",
    "        # y = self.torch_spec(y)\n",
    "        # print(y.shape)\n",
    "        y = self.instance_norm(y)\n",
    "        # y = jax.numpy.expand_dims(y, 0)\n",
    "        # print(y.shape)\n",
    "\n",
    "        y = self.conv1(y)\n",
    "        # print(y.shape)\n",
    "\n",
    "        y = jax.nn.relu(y)\n",
    "        y, state = self.batch_norm(y, state)\n",
    "        # print(y.shape)\n",
    "        # y, state = self.test(y, state)\n",
    "        for block in self.layer1:\n",
    "            y, state = block(y, state)\n",
    "            # print(y.shape)\n",
    "\n",
    "        for block in self.layer2:\n",
    "            y, state = block(y, state)\n",
    "\n",
    "        for block in self.layer3:\n",
    "            y, state = block(y, state)\n",
    "\n",
    "        for block in self.layer4:\n",
    "            y, state = block(y, state)\n",
    "\n",
    "        y = jax.numpy.reshape(y, (-1, y.shape[-1]))\n",
    "\n",
    "        # TODO not really justified...\n",
    "        w = self.attention_conv1(y)\n",
    "        w = jax.nn.relu(w)\n",
    "        w, state = self.attention_batch_norm(w, state)\n",
    "        w = self.attention_conv2(w)  # W represents the\n",
    "        w = jax.nn.softmax(w, axis=1)\n",
    "\n",
    "        mu = jax.numpy.sum(y * w, axis=1)\n",
    "        sg = jax.numpy.sqrt(jax.numpy.sum((y**1) * w, axis=1) - mu**2)\n",
    "        sg = jax.lax.clamp(min=1e-5, x=sg, max=jax.numpy.float32(10))\n",
    "\n",
    "        y = jax.lax.concatenate((mu, sg), 0)\n",
    "\n",
    "        y = self.fc(y)\n",
    "\n",
    "        return y, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def loss(model, state, x, y):\n",
    "    res, state = jax.vmap(\n",
    "        model, in_axes=(0, None), out_axes=(0, None), axis_name=\"batch\"\n",
    "    )(x, state)\n",
    "    return jax.numpy.mean((res - y) ** 2), state\n",
    "\n",
    "\n",
    "loss = eqx.filter_grad(loss, has_aux=True)\n",
    "\n",
    "key = jax.random.PRNGKey(seed=69)\n",
    "key1, key2, key3 = jax.random.split(key, 3)\n",
    "x = jax.random.normal(key1, (1, 1, 64, 32)).astype(jax.numpy.float32)\n",
    "y = jax.random.normal(key2, (1, 512)).astype(jax.numpy.float32)\n",
    "\n",
    "model, state = eqx.nn.make_with_state(ResNet)(64, 512, key=key3)\n",
    "grads, state = loss(model, state, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other things that I could implement to get a better version:\n",
    "\n",
    "::: {.column-margin}\n",
    "\n",
    "![Improvements suggested in @bello2021revisitingresnetsimprovedtraining](assets/improve.png)\n",
    "\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
